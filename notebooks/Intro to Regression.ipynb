{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Regression\n",
    "\n",
    "We're going to start with synthetic data $(x_i,y_i)$, where $\\{x_i\\}$ are known with negligible uncertainty, and $\\{y_i\\}$ values have variable uncertainties $\\{\\sigma_{yi}\\}$.  This data is from [](), and can be downloaded directly with the following:\n",
    "\n",
    "```bash\n",
    "wget -o ../data/data_yerr.dat https://raw.githubusercontent.com/davidwhogg/DataAnalysisRecipes/master/straightline/src/data_yerr.dat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('../data/data_yerr.dat', names=True, comments='#', delimiter='&')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(data['x'], data['y'], yerr=data['sigm_y'], linewidth=0, elinewidth=3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our goal is *linear regression*, we want to find the function $f(x)$ of the form\n",
    "\n",
    "$$\n",
    "f(x) = m x + b\n",
    "$$\n",
    "\n",
    "that best fits the data.\n",
    "\n",
    "We'll start off with the following set of assumptions:\n",
    "1. That the data truly come from a line, $y = f(x) = mx+b$.\n",
    "1. Deviations from the *true* values are only due to errors in the measurement of $y$.\n",
    "1. Those errors are drawn from Gaussian distributions, with $0$ mean and $\\sigma_{y_i}^2$ variances (i.e., $\\mathcal{N}(0, \\sigma_{y_i}^2)$).\n",
    "1. All errors are independent.\n",
    "\n",
    "So, given independent $x_i$, uncertainties $\\sigma_{y_i}$, a slope $m$, an intercept $b$, the distribution of expected values for $y_i$ follows\n",
    "\n",
    "$$\n",
    "p(y_i|x_i, \\sigma_{y_i}, m, b) = \\frac{1}{\\sqrt{2\\pi\\sigma_{yi}^2}}\\exp\\left[-\\frac{[y_i - (mx_i + b)]^2}{2\\sigma_{y_i}^2}\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, we can now determine the line (i.e., parameters $m$ and $b$) that maximizes the probability of the observed data given the model, or the *likelihood*.  Since all data points are assumed to be independent, so the likelihood $\\mathcal{L}$ is just the product of the conditional probabilities.\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\prod_{i=1}^N p(y_i|x_i, \\sigma_{y_i}, m, b)\n",
    "$$\n",
    "\n",
    "It's often convenient to work with the log of probabilities, where\n",
    "\n",
    "$$\n",
    "\\ln \\mathcal{L} = K - \\sum_{i=1}^N\\frac{[y_i - (mx_i-b)]^2}{2\\sigma_{y_i}^2} = K - \\frac{1}{2}\\chi^2\n",
    "$$\n",
    "\n",
    "Looking at this, we can see that maximizing the likelihood is equivilent to minimizing the $\\chi^2$ (i.e., the total squared error, scaled by the uncertainties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(m, b):\n",
    "    def model(x):\n",
    "        return m * x + b\n",
    "    return model\n",
    "\n",
    "def lnlikelihood(m, b, x=data['x'], y=data['y'], sigma_y=data['sigm_y']):\n",
    "    model = build_model(m, b)\n",
    "    lnlike = -.5*np.sum(np.log(2*np.pi*sigma_y**2)) - np.sum((y - model(x))**2/(2*sigma_y**2)) \n",
    "    return lnlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(data['x'], data['y'], yerr=data['sigm_y'], linewidth=0, elinewidth=3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "xlow, xhigh = plt.xlim()\n",
    "test_x = np.linspace(xlow, xhigh, 10)\n",
    "\n",
    "m = 2\n",
    "b = 100\n",
    "model = build_model(m, b)\n",
    "plt.plot(test_x, model(test_x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([m, b])\n",
    "res = minimize(lambda x:-lnlikelihood(x[0], x[1]), x0)\n",
    "\n",
    "best_fit_m = res.x[0]\n",
    "best_fit_b = res.x[1]\n",
    "best_fit_model = build_model(best_fit_m, best_fit_b)\n",
    "\n",
    "print(\"best fit model:\\ny = {:.2f} x + {:.2f}\".format(best_fit_m, best_fit_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(data['x'], data['y'], yerr=data['sigm_y'], linewidth=0, elinewidth=3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.plot(test_x, best_fit_model(test_x))\n",
    "print(\"max likelihood: {}\".format(np.exp(lnlikelihood(best_fit_m, best_fit_b))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, lets look at the likelihood surface over a range of parameter values around the best-fit point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrid = 100\n",
    "\n",
    "mmin, mmax = 0, 3\n",
    "bmin, bmax = -50, 300\n",
    "ms = np.linspace(mmin, mmax, ngrid)\n",
    "bs = np.linspace(bmin, bmax, ngrid)\n",
    "\n",
    "M, B = np.meshgrid(ms, bs)\n",
    "pts = np.column_stack([M.ravel(), B.ravel()])\n",
    "lnL = np.array([lnlikelihood(m, b) for m,b in pts]).reshape(M.shape)\n",
    "plt.imshow(np.exp(lnL), extent=[mmin, mmax, bmin, bmax], origin='lower', aspect='auto')\n",
    "plt.xlabel('$m$')\n",
    "plt.ylabel('$b$')\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('$\\mathcal{L}$')\n",
    "\n",
    "plt.scatter([best_fit_m], [best_fit_b], marker='x', color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
